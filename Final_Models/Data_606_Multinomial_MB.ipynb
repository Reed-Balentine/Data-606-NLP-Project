{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ytuzFF6qAkVg"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dyHItZUL0r1v",
    "outputId": "7467ce3d-b289-468c-caf8-1c455b8716e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'os.chdir(\\'/content\\')\\n!mkdir /root/.kaggle\\n!echo \\'{\"username\":\"daniel1998xx\",\"key\":\"c99226b7cd73b12d4681a78a5b02d227\"}\\' > /root/.kaggle/kaggle.json\\n!kaggle datasets download -d shuyangli94/interview-npr-media-dialog-transcripts\\nif not os.path.exists(\"/content/NPR_Data\"):\\n    os.makedirs(\"/content/NPR_Data\")\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''os.chdir('/content')\n",
    "!mkdir /root/.kaggle\n",
    "!echo '{\"username\":\"daniel1998xx\",\"key\":\"c99226b7cd73b12d4681a78a5b02d227\"}' > /root/.kaggle/kaggle.json\n",
    "!kaggle datasets download -d shuyangli94/interview-npr-media-dialog-transcripts\n",
    "if not os.path.exists(\"/content/NPR_Data\"):\n",
    "    os.makedirs(\"/content/NPR_Data\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0ODUQNk0061i",
    "outputId": "5aa21857-ee70-47ab-8e97-1515415128a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!unzip interview-npr-media-dialog-transcripts.zip -d NPR_Data'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''!unzip interview-npr-media-dialog-transcripts.zip -d NPR_Data'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "gsH5NyNb09VR"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"os.chdir('/content/NPR_Data')\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''os.chdir('/content/NPR_Data')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "6H4d5re61Avm"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('utterances.csv')\n",
    "df['speaker'] = df['speaker'].str.upper()\n",
    "df['speaker'] = df['speaker'].str.split(', H', expand=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "W5H_Tbfr1Hff"
   },
   "outputs": [],
   "source": [
    "df = df[df['speaker'] != '_NO_SPEAKER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Kc-QXD2w1Mw7"
   },
   "outputs": [],
   "source": [
    "df['utterance_len'] = df['utterance'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "J0rAadft1PJU"
   },
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "host_id_df = pd.read_json('host_id.json', orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "5yrjY_Dk1S_l"
   },
   "outputs": [],
   "source": [
    "host_id_df = pd.read_json('host_id.json', orient='index')\n",
    "host_id_df.reset_index(inplace=True)\n",
    "host_id_df = host_id_df.rename(columns = {'index':'speaker'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "1QR0CsBQ1THr"
   },
   "outputs": [],
   "source": [
    "host_id_df['speaker'] = host_id_df['speaker'].astype('string')\n",
    "host_id_df['speaker'] = host_id_df['speaker'].str.upper()\n",
    "host_id_df.rename(columns={0:'host_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "P9iSdtlF1Xsd"
   },
   "outputs": [],
   "source": [
    "mergedf = df.merge(host_id_df, how='left', on='speaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "MqLRrUFY1fgg"
   },
   "outputs": [],
   "source": [
    "mergedf['host_id'] = mergedf['host_id'].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ixfvWhyziJzI"
   },
   "outputs": [],
   "source": [
    "PreProcess_df = mergedf[mergedf['host_id'] != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "IdhlVuKwiPtG"
   },
   "outputs": [],
   "source": [
    "PreProcess_df = PreProcess_df.loc[PreProcess_df['utterance_len'] >= 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "DXyfBNuBiUu1"
   },
   "outputs": [],
   "source": [
    "top_speakers = PreProcess_df.groupby(['speaker']).size().loc[PreProcess_df.groupby(['speaker']).size() > 20000]\n",
    "df = pd.DataFrame(PreProcess_df.loc[PreProcess_df['speaker'].isin(top_speakers.index.values)])\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "uZ600FV9ihQF"
   },
   "outputs": [],
   "source": [
    "df['utterance'] = df['utterance'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "ScuJvIYqij7S"
   },
   "outputs": [],
   "source": [
    "df['unidentified'] = df['utterance'].str.startswith('unidentified')\n",
    "df = df[df['unidentified'] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3AsQHfUDKQaw",
    "outputId": "22f099aa-1ed1-4033-b264-59edab5f43a5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "episode          289355\n",
       "episode_order    289355\n",
       "speaker          289355\n",
       "utterance        289355\n",
       "utterance_len    289355\n",
       "host_id          289355\n",
       "unidentified     289355\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1wbgSYxaW78S",
    "outputId": "27371101-6ffe-44b3-832c-38056c2093d5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NEAL CONAN        126971\n",
       "STEVE INSKEEP      33787\n",
       "ROBERT SIEGEL      29948\n",
       "IRA FLATOW         29888\n",
       "FARAI CHIDEYA      23937\n",
       "MELISSA BLOCK      23134\n",
       "RENEE MONTAGNE     21690\n",
       "Name: speaker, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['speaker'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hr0QPv7-HjnS",
    "outputId": "7f79325b-ade1-4a1a-e933-d8963de84490"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NEAL CONAN        34000\n",
       "STEVE INSKEEP     33787\n",
       "ROBERT SIEGEL     29948\n",
       "IRA FLATOW        29888\n",
       "FARAI CHIDEYA     23937\n",
       "MELISSA BLOCK     23134\n",
       "RENEE MONTAGNE    21690\n",
       "Name: speaker, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.groupby('speaker').apply(lambda x: x.sample(34000) if x['speaker'].iloc[0] == 'NEAL CONAN' else x)\n",
    "df['speaker'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2WGgiwULI947",
    "outputId": "5c5fa0bb-40e9-4e7f-fb12-591c218bf8e9"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nltk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-1f5a6b09e6a9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'stopwords'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'wordnet'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'omw-1.4'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nltk' is not defined"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords') \n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pu_SDd3ai4iW"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "upvijMxLrBeF"
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    tokeniser = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokeniser.tokenize(text)\n",
    "\n",
    "    lemmatiser = WordNetLemmatizer()\n",
    "    lemmas = [lemmatiser.lemmatize(token.lower(), pos='v') for token in tokens]\n",
    "\n",
    "    keywords= [lemma for lemma in lemmas if lemma not in stopwords.words('english')]\n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IzpQvZKJsqQd"
   },
   "outputs": [],
   "source": [
    "utterance_list = df['utterance'].to_list()\n",
    "final_list = []\n",
    "complete_list = []\n",
    "for utterance in utterance_list:\n",
    "    processed = preprocess_text(utterance)\n",
    "    final_list.append(processed)\n",
    "complete_list.extend(final_list)\n",
    "df['processed_utterance'] = complete_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "880UIXhULHcL"
   },
   "outputs": [],
   "source": [
    "df['processed_utterance'] = df['processed_utterance'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mmsDEU6yLPIq"
   },
   "outputs": [],
   "source": [
    "df.to_pickle(\"processed_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W4K_umOdLbWE"
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"processed_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DiECXIAHtkCe"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "95UR1E_u4ErJ"
   },
   "outputs": [],
   "source": [
    "X = df.processed_utterance\n",
    "y = df.speaker\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tPDGj2jM4Wjr"
   },
   "outputs": [],
   "source": [
    "vector = TfidfVectorizer(analyzer='word', max_features = 850, ngram_range=(1, 1), \n",
    "                       binary=False, norm=None, smooth_idf=True, strip_accents=None,\n",
    "                       sublinear_tf=True, use_idf=False)\n",
    "\n",
    "df_transformed = vector.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ka2OxIKvLmBp"
   },
   "outputs": [],
   "source": [
    "multi_nb_model = MultinomialNB()\n",
    "multi_nb_model.fit(df_transformed, y_train)\n",
    "print (\"Model accuracy within dataset: \", multi_nb_model.score(df_transformed, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jSaCV5SdL2Iw"
   },
   "outputs": [],
   "source": [
    "print(classification_report(cross_valmodel_pred_pd[\"label\"], cross_valmodel_pred_pd[\"prediction\"]))\n",
    "print(accuracy_score(cross_valmodel_pred_pd[\"label\"], cross_valmodel_pred_pd[\"prediction\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d-XPGR9_Lynp"
   },
   "outputs": [],
   "source": [
    "test_text = [\"So for a top competitor like Lance to try to\"]\n",
    "test_text_transform = vector.transform(test_text)\n",
    "\n",
    "print (multi_nb_model.predict(test_text_transform),\" most likely said it.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_zMSxj4xL2Ge"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "htK5lnVQL2Dp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hCBC0tPWL2Ag"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OC04TPUC4KYv",
    "outputId": "d592a57f-375b-4b45-8a81-547f5cba84b1"
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
    "pipe.steps\n",
    "\n",
    "param_grid = {}\n",
    "param_grid[\"tfidfvectorizer__max_features\"] = [500, 1000, 15000]\n",
    "param_grid[\"tfidfvectorizer__ngram_range\"] = [(1,1), (1,2), (2,2)]\n",
    "#param_grid[\"tfidfvectorizer__stop_words\"] = [\"english\", None]\n",
    "param_grid[\"tfidfvectorizer__strip_accents\"] = [\"ascii\", \"unicode\", None]\n",
    "param_grid[\"tfidfvectorizer__analyzer\"] = [\"word\", \"char\"]\n",
    "param_grid[\"tfidfvectorizer__binary\"] = [True, False]\n",
    "param_grid[\"tfidfvectorizer__norm\"] = [\"l1\", \"l2\", None]\n",
    "param_grid[\"tfidfvectorizer__use_idf\"] = [True, False]\n",
    "param_grid[\"tfidfvectorizer__smooth_idf\"] = [True, False]\n",
    "param_grid[\"tfidfvectorizer__sublinear_tf\"] = [True, False]\n",
    "\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv=5, scoring='accuracy', verbose = 3, n_jobs = -1)\n",
    "grid.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "aJQLErWG6BsZ",
    "outputId": "1b9156c9-06c5-4b0d-91ae-6e70850c58bc"
   },
   "outputs": [],
   "source": [
    "grid.fit(X_train,y_train)\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
